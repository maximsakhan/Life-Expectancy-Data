{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Life Expectancy Prediction\n\nThe aim of this study is to investigate the determinants of life expectancy with the purpose of identifying the most significant factors that impact it. The selected factors will then be used as predictors in a predictive model. The analysis will involve a two-stage approach consisting of variable selection algorithms followed by regression algorithms, including LASSO and RIDGE.","metadata":{}},{"cell_type":"markdown","source":"To initiate the analysis, we will first import the dataset into R and proceed to examine its underlying structure.","metadata":{}},{"cell_type":"code","source":"library(tidyverse) # metapackage of all tidyverse packages\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(corrplot)\nlibrary(leaps)\nlibrary(caret)\nlibrary(glmnet)\n\n# Load the data into a dataframe called 'life_expectancy'\nlife_expectancy  <- read.csv(\"/kaggle/input/life-expectancy-who/Life Expectancy Data.csv\")\n","metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle","execution":{"iopub.status.busy":"2023-09-19T05:03:51.150917Z","iopub.execute_input":"2023-09-19T05:03:51.153844Z","iopub.status.idle":"2023-09-19T05:03:51.277998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# View the first few rows of the dataset \nhead(life_expectancy)\n\n# Check the dimensions of the dataset (rows, columns)\ndim(life_expectancy)\n\n# Get a summary of the variables in the dataset\nsummary(life_expectancy)\n\n# Check for missing values\nsum(is.na(life_expectancy))","metadata":{"execution":{"iopub.status.busy":"2023-09-19T05:03:51.282769Z","iopub.execute_input":"2023-09-19T05:03:51.284655Z","iopub.status.idle":"2023-09-19T05:03:51.363095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Handle missing data\nlife_expectancy <- na.omit(life_expectancy)\n\n# Transform variables\nlife_expectancy$Year <- as.factor(life_expectancy$Year)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T05:03:51.366104Z","iopub.execute_input":"2023-09-19T05:03:51.367642Z","iopub.status.idle":"2023-09-19T05:03:51.386299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize life expectancy by country and status\noptions(repr.plot.width = 25, repr.plot.height = 15)\nggplot(life_expectancy, aes(x = Country, y = Life.expectancy, fill = Status)) +\n  geom_boxplot(outlier.alpha = 0.1) +\n  labs(title = \"Life Expectancy by Country and Status\",\n       x = \"Country\",\n       y = \"Life Expectancy (years)\",\n       fill = \"Status\") +\n  theme(plot.title = element_text(size = 20, hjust = 0.5),\n        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, size=12),\n        legend.position = \"bottom\")\n","metadata":{"execution":{"iopub.status.busy":"2023-09-19T05:03:51.389222Z","iopub.execute_input":"2023-09-19T05:03:51.390706Z","iopub.status.idle":"2023-09-19T05:03:53.911540Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"While the plot's message may not be immediately obvious, its primary objective is to underscore the influential role of a country's status in shaping life expectancy rates, as evident from the depicted data. Furthermore, it highlights that several nations, including Austria, Canada, Germany, Greece, and Ireland, consistently rank among the highest in terms of life expectancy.","metadata":{}},{"cell_type":"code","source":"life_expectancy <- life_expectancy %>%\n    select(-Country, - Year)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T05:03:53.914371Z","iopub.execute_input":"2023-09-19T05:03:53.915816Z","iopub.status.idle":"2023-09-19T05:03:53.932335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"life_expectancy$Status <- factor(life_expectancy$Status)\n\n# Select numerical columns for correlation matrix\nnum_cols <- sapply(life_expectancy, is.numeric)\ncor_mat <- cor(life_expectancy[, num_cols])\n\n# Visualize correlation matrix\ncorrplot(cor_mat, method = \"circle\", type = \"upper\", tl.col = \"black\", tl.srt = 45)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T05:03:53.935102Z","iopub.execute_input":"2023-09-19T05:03:53.936550Z","iopub.status.idle":"2023-09-19T05:03:54.399371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Analyzing the correlation matrix provided, it becomes evident that life expectancy exhibits strong correlations with various factors, including Income Composition Of Resources, Schooling, BMI, HIV, and Adult Mortality. This observation raises concerns about potential multicollinearity issues within our model. Consequently, to address this concern, we intend to mitigate the problem by eliminating redundant variables such as Infant Deaths and Under Five Deaths, as well as others displaying similarly high correlations, as illustrated in the matrix above.","metadata":{}},{"cell_type":"code","source":"life_expectancy <- life_expectancy %>%\n    select(-under.five.deaths, -percentage.expenditure, -thinness.5.9.years)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T05:03:54.402217Z","iopub.execute_input":"2023-09-19T05:03:54.403792Z","iopub.status.idle":"2023-09-19T05:03:54.422162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"$$\n\\begin{align*}\n1. & \\text{Start with an empty set of selected predictor variables: } S = \\emptyset. \\\\\n2. & \\text{Initialize a model with no predictors: } M_0. \\\\\n3. & \\text{For } k = 1 \\text{ to } p \\text{ (where } p \\text{ is the total number of predictors):} \\\\\n   & \\quad \\text{a. For each predictor } X_j \\text{ not in } S, \\text{ fit the model } M_k \\text{ with the predictors in } S \\text{ plus } X_j \\\\\n   & \\quad \\text{and calculate a performance metric (e.g., AIC, BIC, or p-value).} \\\\\n   & \\quad \\text{b. Select the predictor } X_j \\text{ that improves the performance metric the most and add it to } S. \\\\\n4. & \\text{Continue the loop until a stopping criterion is met (e.g., no further improvement in the performance metric).} \\\\\n5. & \\text{The final model contains the selected predictors: } M_{\\text{final}}.\n\\end{align*}\n$$","metadata":{}},{"cell_type":"code","source":"# Stepwise forward selection omitting country and year columns\nregfit.fwd <- regsubsets(Life.expectancy ~ ., data = life_expectancy, nvmax = ncol(life_expectancy)-1, method = \"forward\")\nsummary(regfit.fwd)","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2023-09-19T05:03:54.426873Z","iopub.execute_input":"2023-09-19T05:03:54.428632Z","iopub.status.idle":"2023-09-19T05:03:54.460369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Handle missing data\nlife_expectancy_clean <- na.omit(life_expectancy)\n\n# Split the data into training and testing sets\nset.seed(123)\ntrainIndex <- createDataPartition(life_expectancy_clean$Life.expectancy, \n                                   p = 0.8, list = FALSE)\ntrainData <- life_expectancy_clean[trainIndex, ]\ntestData <- life_expectancy_clean[-trainIndex, ]\n\n# Define the predictor variables\npredictors <- names(life_expectancy_clean)[4:19]\n\n# Set the maximum number of predictors to consider\nmax_n <- length(predictors)\n\n# Create an empty data frame to store the RMSE values\nrmse_df <- data.frame(nvmax = 1:max_n, RMSE = NA)\n\npredict.regsubsets = function(object, newdata, id, ...) {\n    form = as.formula(object$call[[2]])\n    mat = model.matrix(form, newdata)\n    coefi = coef(object, id = id)\n    mat[, names(coefi)] %*% coefi\n}\n\n# Run the stepwise forward algorithm for different values of nvmax\nfor (i in 1:max_n) {\n    model <- regsubsets(Life.expectancy ~ ., data = trainData,\n                      nvmax = i, method = \"forward\")\n    pred <- predict(model, testData, i)\n    rmse_df[i, \"RMSE\"] <- RMSE(pred, testData$Life.expectancy)\n}\n","metadata":{"execution":{"iopub.status.busy":"2023-09-19T05:03:54.464660Z","iopub.execute_input":"2023-09-19T05:03:54.466273Z","iopub.status.idle":"2023-09-19T05:03:54.684305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the RMSE values against the number of predictors\nlibrary(ggplot2)\nggplot(rmse_df, aes(x = nvmax, y = RMSE)) +\n  geom_line() +\n  labs(x = \"Number of predictors\", y = \"RMSE\") +\n  theme_bw() +\n  scale_x_continuous(breaks = seq(1, max_n, by = 1))","metadata":{"execution":{"iopub.status.busy":"2023-09-19T05:03:54.688819Z","iopub.execute_input":"2023-09-19T05:03:54.690505Z","iopub.status.idle":"2023-09-19T05:03:55.201027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As demonstrated by the stepwise forward variable selection algorithm, the ideal number of predictors appears to be seven. This conclusion is supported by a noticeable dip in the Root Mean Squared Error (RMSE) when considering the number of predictors. Beyond this point, the inclusion of additional predictors contributes to model complexity without a corresponding improvement in RMSE. Consequently, it is reasonable to assert that a robust model can be crafted by leveraging the insights gleaned from the summary of the regsubsets output, which highlights the significance of these seven variables.","metadata":{}},{"cell_type":"code","source":"stepwise_model <- lm(Life.expectancy~Schooling+Income.composition.of.resources+Schooling*Income.composition.of.resources+\n                     GDP+HIV.AIDS+Diphtheria+BMI+Adult.Mortality,data=trainData)\npred <- predict(stepwise_model, testData[,-1])\nRMSE(pred, testData$Life.expectancy)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T05:03:55.205620Z","iopub.execute_input":"2023-09-19T05:03:55.208119Z","iopub.status.idle":"2023-09-19T05:03:55.234586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The optimized linear regression model demonstrates an RMSE of 3.73, indicating its effectiveness. An essential consideration in this model's development was the substantial correlation observed between the predictor variables, Income Composition Of Resources and Schooling. To address this multicollinearity, an interaction term was introduced into the model. This strategic step enables us to capture the nuanced interplay between predictor variables and understand how their effects depend on one another.","metadata":{}},{"cell_type":"code","source":"X <- as.matrix(scale(trainData[,-c(1,2)]))\nY <- trainData$Life.expectancy\n\n# Fit LASSO model\nlasso_model <- glmnet(X, Y, alpha = 1)\n\n# Fit Ridge model\nridge_model <- glmnet(X, Y, alpha = 0)\n\n# Cross-validation for LASSO\ncv_lasso <- cv.glmnet(X, Y, alpha = 1, nfolds = 5)\n\n# Cross-validation for Ridge\ncv_ridge <- cv.glmnet(X, Y, alpha = 0, nfolds = 5)\n\n# Optimal lambda for LASSO\noptimal_lambda_lasso <- cv_lasso$lambda.min\n\n# Optimal lambda for Ridge\noptimal_lambda_ridge <- cv_ridge$lambda.min","metadata":{"execution":{"iopub.status.busy":"2023-09-19T05:03:55.238826Z","iopub.execute_input":"2023-09-19T05:03:55.240441Z","iopub.status.idle":"2023-09-19T05:03:55.413300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"$$\n\\text{Lasso}(L1) = \\lambda \\sum_{j=1}^{p} |\\beta_j|\n$$\n$$\n\\text{Ridge}(L2) = \\lambda \\sum_{j=1}^{p} \\beta_j^2\n$$","metadata":{}},{"cell_type":"code","source":"# Refit the models with the optimal lambda\nlasso_model_optimal <- glmnet(X, Y, alpha = 1, lambda = optimal_lambda_lasso)\nridge_model_optimal <- glmnet(X, Y, alpha = 0, lambda = optimal_lambda_ridge)\n\n# Predictions using LASSO\npredictions_lasso <- predict(lasso_model_optimal, newx = as.matrix(scale(testData[,-c(1,2)])))\nrmse_lasso <- sqrt(mean((predictions_lasso - testData$Life.expectancy)^2))\n\n# Predictions using Ridge\npredictions_ridge <- predict(ridge_model_optimal, newx = as.matrix(scale(testData[,-c(1,2)])))\nrmse_ridge <- sqrt(mean((predictions_ridge - testData$Life.expectancy)^2))\n\nrmse_lasso\nrmse_ridge","metadata":{"execution":{"iopub.status.busy":"2023-09-19T05:03:55.417729Z","iopub.execute_input":"2023-09-19T05:03:55.419354Z","iopub.status.idle":"2023-09-19T05:03:55.466532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The rmse_lasso stands at 3.72, while rmse_ridge is 3.70, indicating that Ridge outperforms both Stepwise and Lasso. During 5-fold cross-validation, both Lasso and Ridge models exhibit superior performance compared to the Stepwise linear model. The final model to explore is the Elastic Net, which combines elements of both Lasso and Ridge models.","metadata":{}},{"cell_type":"markdown","source":"$$\\text{Elastic Net}(L1L2) = \\lambda_1 \\sum_{j=1}^{p} |\\beta_j| + \\lambda_2 \\sum_{j=1}^{p} \\beta_j^2$$","metadata":{}},{"cell_type":"code","source":"elastic_net_model <- glmnet(X, Y, alpha = 0.5)\ncv_elastic_net <- cv.glmnet(X, Y, alpha = 0.5)\noptimal_lambda <- cv_elastic_net$lambda.min\noptimal_elastic_net_model <- glmnet(X, Y, alpha = 0.5, lambda = optimal_lambda)\npredictions_elastic <- predict(optimal_elastic_net_model, newx = as.matrix(scale(testData[,-c(1,2)])))\nrmse_elastic <- sqrt(mean((predictions_elastic - testData$Life.expectancy)^2))\nrmse_elastic","metadata":{"execution":{"iopub.status.busy":"2023-09-19T05:03:55.470668Z","iopub.execute_input":"2023-09-19T05:03:55.472598Z","iopub.status.idle":"2023-09-19T05:03:55.618951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As observed, the performance of the Elastic Net model is notably inferior to that of Ridge. This outcome aligns with our earlier expectations, given that Lasso, which is a component of the Elastic Net, didn't perform as strongly as Ridge in the prior assessment. Consequently, we can confidently assert that the optimal model choice continues to be Ridge, boasting an RMSE of 3.70, which represents its superior characteristics. Below, you'll find the model summary for Ridge:","metadata":{}},{"cell_type":"code","source":"coef(ridge_model_optimal)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T05:03:55.623105Z","iopub.execute_input":"2023-09-19T05:03:55.624678Z","iopub.status.idle":"2023-09-19T05:03:55.645135Z"},"trusted":true},"execution_count":null,"outputs":[]}]}